{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import operator\n",
    "#import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Set up Output File\n",
    "outdir = '..//data//clean_data'\n",
    "\n",
    "##### Contain 2 column : 1. Replaced name of entity / 2. Real name of entity\n",
    "reverse_entity = open(os.path.join(outdir,os.path.basename('entity_total.csv')),'w',encoding='utf-8') \n",
    "\n",
    "#####\n",
    "#entity_replaced = open(os.path.join(outdir,os.path.basename('entity_replaced_4.csv')),'w',encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Trigger word\n",
    "triggers_raw = open('..//data//preprocessing/triggers.txt').read().split('\\n')[:-1]\n",
    "triggers = []\n",
    "for row in triggers_raw :\n",
    "    triggers.append(ps.stem(row.split('\\t')[-1]))\n",
    "    \n",
    "triggers = list(set(triggers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Entity sources\n",
    "\n",
    "#### Drug synonyms from drugbank\n",
    "#drugs = json.load(open('..//data/preprocessing/drug_corpus/drug_name_synonyms.json',encoding='utf-8'))\n",
    "drugs = json.load(open('..//data/preprocessing/drug_corpus/drugs.json',encoding='utf-8'))\n",
    "#### Herb scientific name and its synonyms (not alias)\n",
    "#herbs = json.load(open('..//data/preprocessing/herb_corpus/herb_science_synonyms.json',encoding='utf-8'))\n",
    "herbs = json.load(open('..//data/preprocessing/herb_corpus/herb_syms_total.json',encoding='utf-8'))\n",
    "#### standard ref without effect\n",
    "ref_without = json.load(open('..//data/preprocessing/standard_ref/standard_ref_without_effect.json',encoding='utf-8'))\n",
    "\n",
    "#### standard ref with effect\n",
    "#ref_effect = open('..//data/preprocessing/standard_ref/standard_ref_effect.csv').read().split('\\n')[:-1]\n",
    "\n",
    "#### Adverse effect corpus\n",
    "#adverse_effect = json.load(open('..//data/preprocessing/adverse_effect_corpus/adverse_effect.json'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Create name for entity\n",
    "\n",
    "###### trigger entity\n",
    "#trigger_entity = {}\n",
    "#for each in triggers :\n",
    "#    trigger_entity[each] = 'trigger_entity'\n",
    "#    reverse_entity.write('trigger_entity\\t%s\\n'%each)\n",
    "\n",
    "###### Drug entity\n",
    "drug_entity = {}\n",
    "drugorder = 0\n",
    "for ID in drugs :\n",
    "    for drug in drugs[ID] :\n",
    "        if drug.lower() in herbs or drug.lower() in ref_without :\n",
    "            break\n",
    "        drug_entity[drug.lower()] = 'drug_entity_%s'%drugorder\n",
    "        try :\n",
    "            reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drug.lower()))\n",
    "        except :\n",
    "            drugencode = str(drug.lower()).encode('utf8')\n",
    "            reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drugencode))\n",
    "    drugorder+=1\n",
    "\n",
    "###### Herb entity \n",
    "herb_entity = {}\n",
    "herborder = 0\n",
    "for herb in herbs :\n",
    "    #herb_entity[herb.lower()] = 'herb_entity_%s'%herborder\n",
    "    reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herb.lower()))\n",
    "    for synonym in herbs[herb] :\n",
    "        herb_entity[synonym.lower()] = 'herb_entity_%s'%herborder\n",
    "        try :\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,synonym.lower()))\n",
    "        except :\n",
    "            herbencode = str(synonym.lower()).encode('utf8')\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herbencode))\n",
    "    herborder+=1\n",
    "    \n",
    "###### Adverse effect entity\n",
    "#effect_entity = {}\n",
    "#effectorder = 0\n",
    "#for each in adverse_effect :\n",
    "#    effect_entity[each.lower()] = 'EF_entity_%s'%effectorder\n",
    "#    try :\n",
    "#        reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,each.lower()))\n",
    "#    except :\n",
    "#        effectencode = str(each.lower()).encode('utf8')\n",
    "#        reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "#    effectorder+=1\n",
    "    \n",
    "###### standard ref without effect entity \n",
    "for herb in ref_without :\n",
    "    if herb.lower() not in herb_entity :\n",
    "        herb_entity[herb.lower()] = 'herb_entity_%s'%herborder\n",
    "        try :\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herb.lower()))\n",
    "        except :\n",
    "            herbencode = str(herb.lower()).encode('utf8')\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herbencode))\n",
    "        herborder+=1\n",
    "    for drug in ref_without[herb] :\n",
    "        if drug.lower() not in drug_entity :\n",
    "            drug_entity[drug.lower()] = 'drug_entity_%s'%drugorder\n",
    "            try :\n",
    "                reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drug.lower()))\n",
    "            except :\n",
    "                drugencode = str(drug.lower()).encode('utf8')\n",
    "                reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drugencode))\n",
    "            drugorder+=1\n",
    "            \n",
    "###### standard ref with effect\n",
    "''''''\n",
    "#for row in ref_effect :\n",
    "#    effect = row.split('\\t')[2]\n",
    "#    ###\n",
    "#    if effect.lower() not in effect_entity :\n",
    "#        effect_entity[effect.lower()] = 'EF_entity_%s'%effectorder\n",
    "#        try :\n",
    "#            reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,effect.lower()))\n",
    "#        except :\n",
    "#            effectencode = str(effect.lower()).encode('utf8')\n",
    "#            reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "#        effectorder+=1\n",
    "#    ###    \n",
    "#    if len(row.split('\\t')) == 4 :\n",
    "#        effect1 = row.split('\\t')[3]\n",
    "#        if effect1.lower() not in effect_entity :\n",
    "#            effect_entity[effect1.lower()] = 'EF_entity_%s'%effectorder\n",
    "#            try :\n",
    "#                reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,effect1.lower()))\n",
    "#            except :\n",
    "#                effectencode = str(effect1.lower()).encode('utf8')\n",
    "#                reverse_entity.write('EF_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "#            effectorder+=1\n",
    "''''''\n",
    "######\n",
    "reverse_entity.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### remove '\\n' from text and merge text\n",
    "def rmv_n(textdict) :\n",
    "    begin = time.time()\n",
    "    text = ''\n",
    "    print('merge text')\n",
    "    count = 0\n",
    "    for each in textdict :\n",
    "        if len(textdict[each].split('\\n')) != 1 :\n",
    "            new = ''.join(textdict[each].split('\\n'))\n",
    "            text+=new\n",
    "        else:\n",
    "            text+= textdict[each]\n",
    "        if count % 1000 == 0 :\n",
    "            print('%s / %s'%(count,len(textdict)))\n",
    "        count+=1\n",
    "    text = text.lower()\n",
    "    print(time.time() - begin)\n",
    "    print('merge text done')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### remove '\\n' from text and merge text\n",
    "def rmv_n(textdict) :\n",
    "    begin = time.time()\n",
    "    text = ''\n",
    "    print('merge text')\n",
    "\n",
    "    #text = ''.join(''.join(operator.itemgetter(*list(textdict))(textdict)).split('\\n')).lower()\n",
    "    \n",
    "    #text = ''.join(''.join([textdict[x] for x in list(textdict)]).split('\\n')).lower()\n",
    "    #text =  ''.join([''.join(x.split('\\n')) for sublist in textdict for x in sublist ])\n",
    "    text = ''.join([textdict[x].replace('\\n',' ') for x in list(textdict)])\n",
    "    print(time.time() - begin)\n",
    "    print('merge text done')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Entity replacement\n",
    "def entity_replace(text) :\n",
    "    ###\n",
    "    begin = time.time()\n",
    "    ###\n",
    "    count = 0\n",
    "    print('herb')\n",
    "    for herb in herb_entity :\n",
    "        if herb in text :\n",
    "            text = text.replace(' %s '%herb,' %s '%herb_entity[herb])\n",
    "            #re.sub(herb,herb_entity[herb],text)\n",
    "            #if herb not in replaced_list :\n",
    "                #entity_replaced.write('%s\\t%s\\n'%(herb_entity[herb],herb))\n",
    "                #replaced_list.append(herb)\n",
    "        if count % 10000 == 0 :\n",
    "            print('%s / %s'%(count,len(herb_entity)))\n",
    "        count+=1\n",
    "    print('herb done')\n",
    "    \n",
    "    ###\n",
    "    drug_entity_single = {}\n",
    "    count = 0\n",
    "    print('drug')\n",
    "    for drug in drug_entity :\n",
    "        if drug in text :\n",
    "            text = text.replace(' %s '%drug,' %s '%drug_entity[drug])\n",
    "            #re.sub(drug,drug_entity[drug],text)\n",
    "            #if drug not in replaced_list :\n",
    "                #entity_replaced.write('%s\\t%s\\n'%(drug_entity[drug],drug))\n",
    "                #replaced_list.append(drug)\n",
    "        #else:\n",
    "            #drug_entity_single[drug] = drug_entity[drug]\n",
    "        if count % 10000 == 0 :\n",
    "            print('%s / %s'%(count,len(drug_entity)))\n",
    "        count+=1\n",
    "    print('drug done')\n",
    "    ###\n",
    "#    print('effect')\n",
    "#    count = 0\n",
    "#    for effect in effect_entity :\n",
    "#        if effect in text :\n",
    "#            text = text.replace(effect,' %s '%effect_entity[effect])\n",
    "#            #re.sub(effect,effect_entity[effect],text)\n",
    "#            if effect not in replaced_list :\n",
    "#                entity_replaced.write('%s\\t%s\\n'%(effect_entity[effect],effect))\n",
    "#                replaced_list.append(effect)\n",
    "#        if count % 1000 == 0 :\n",
    "#            print('%s / %s'%(count,len(drug_entity)))\n",
    "#        count+=1\n",
    "#    print('effect done')\n",
    "    ###\n",
    "#    for trig in trigger_entity:\n",
    "#        if trig in text:\n",
    "#            text = text.replace(trig,' %s '%trigger_entity[trig])\n",
    "            #re.sub(trig,trigger_entity[trig],text)\n",
    "#            if trig not in replaced_list :\n",
    "#                entity_replaced.write('%s\\t%s\\n'%(trigger_entity[trig],trig))\n",
    "#                replaced_list.append(effect)\n",
    "#    print('trigger done')\n",
    "    print(time.time() - begin)\n",
    "    print('replace entities done')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [4, 5, 6], [4, 5, 6]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3,4],[4,5,6,7],[3,4,5,6]]\n",
    "b = [4,5,6,7]\n",
    "c = [3,4,5,6]\n",
    "\n",
    "[ [ i for i in each if i in b and i in c ] for each in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## word processing and word removal\n",
    "#stop_words = list(set(stopwords.words('english')))\n",
    "#punctuations = string.punctuation\n",
    "\n",
    "stop_and_punctuations = list(set(stopwords.words('english'))) + [i for i in string.punctuation ]\n",
    "\n",
    "\n",
    "def word_processing(text,track,stop_and_punctuations) :\n",
    "    begin = time.time()\n",
    "    count = 0\n",
    "    #outdir = '..//data//clean_data//noun_verb'\n",
    "    outdir = '..//data//clean_data//'\n",
    "    subtrack = 0\n",
    "    ######\n",
    "    Pos_accept = ['N','V']\n",
    "    \n",
    "    ###### Split text into words\n",
    "    #words = nltk.pos_tag(word_tokenize(text))\n",
    "    #text = ''\n",
    "    sentences = [ x for x in TextBlob(text).sentences if len(x.split()) > 3 ]\n",
    "    total = len(sentences)\n",
    "    print('Processing %s sentences'%total)\n",
    "    #######\n",
    "    sentences_noun_verb = []\n",
    "    ########\n",
    "    sentence_noun_verb = []\n",
    "    ###### Processing\n",
    "    sentences_noun_verb = [ [word[0] for word in sentence.tags if word[1][0] in Pos_accept and word[0] not in stop_and_punctuations ]  for sentence in sentences ]\n",
    "    \n",
    "    ##### \n",
    "    print(time.time() - begin)\n",
    "    print('Word processed done')\n",
    "\n",
    "    ##### Noun verb\n",
    "    #outdir = '..//data//clean_data//noun_verb'\n",
    "    outfile = open(os.path.join(outdir,os.path.basename('processed_sentences_%s.json'%track)),'w')\n",
    "    outfile.write(json.dumps(sentences_noun_verb))\n",
    "    outfile.close()\n",
    "    sentences_noun_verb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## word processing and word removal\n",
    "def word_processing(text) :\n",
    "    begin = time.time()\n",
    "    count = 0\n",
    "\n",
    "    ###### Create pos_tag accept list and stop words list \n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    pos_tag_accept = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "\n",
    "    ###### Create entity list \n",
    "    reverse_entity = open('..//data/clean_data/entity_total.csv').read().split('\\n')[:-1]\n",
    "    entity_list = []\n",
    "    for row in reverse_entity :\n",
    "        entity_list.append(row.split('\\t')[0])\n",
    "\n",
    "    entity_list = list(set(entity_list))\n",
    "\n",
    "    ###### Split text into sentences\n",
    "    sentences = TextBlob(text).sentences\n",
    "    total = len(sentences)\n",
    "    print('Processing %s sentences'%total)\n",
    "    sentences_processed = []\n",
    "\n",
    "    ###### Processing\n",
    "    for sentence in sentences :          \n",
    "        words = word_tokenize(str(sentence)) ##### Split sentence into words \n",
    "        #####\n",
    "        if len(set(words).intersection(entity_list)) > 2 : ##### Choose sentence contain more than 2 entities\n",
    "            for word in words :\n",
    "                if word in stop_words : ##### Remove stop words\n",
    "                    words.pop(words.index(word))\n",
    "                elif len(word) == 1 : ##### Remove punctuation marks\n",
    "                    words.pop(words.index(word))    \n",
    "            ###\n",
    "            tags = nltk.pos_tag(words)\n",
    "            for tag in tags :\n",
    "                if tag[0] in entity_list : ##### Save entities\n",
    "                    pass      \n",
    "                elif tag[1] not in pos_tag_accept : ##### Remove words which are not noun,verb, and adjective \n",
    "                    words.pop(words.index(tag[0]))\n",
    "            ###\n",
    "            if len(words) > 3 : ###### Save processed sentence\n",
    "                sentences_processed.append(words)\n",
    "        ###\n",
    "        if count % 10000 == 0 :\n",
    "            print('Processed %s sentences'%count)\n",
    "        count+=1\n",
    "\n",
    "    ##### \n",
    "    print(time.time() - begin)\n",
    "    print('Word processed done')\n",
    "    return sentences_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('..//data/abstract_full/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing loop 1352\n",
      "merge text\n",
      "0.04700279235839844\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "910.2992806434631\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 71398 sentences\n",
      "1166.073175907135\n",
      "Word processed done\n",
      "Processing loop 1353\n",
      "merge text\n",
      "0.04900646209716797\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "981.9464514255524\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 72429 sentences\n",
      "1177.6457080841064\n",
      "Word processed done\n",
      "Processing loop 1354\n",
      "merge text\n",
      "0.11700987815856934\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1654.1089470386505\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 70724 sentences\n",
      "1158.3177621364594\n",
      "Word processed done\n",
      "Processing loop 1355\n",
      "merge text\n",
      "0.0370023250579834\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1017.8311252593994\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 76414 sentences\n",
      "1260.9511563777924\n",
      "Word processed done\n",
      "Processing loop 1356\n",
      "merge text\n",
      "0.0350041389465332\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "749.9780232906342\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 56358 sentences\n",
      "926.3594326972961\n",
      "Word processed done\n",
      "Processing loop 1357\n",
      "merge text\n",
      "0.03000187873840332\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "793.0970637798309\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 57105 sentences\n",
      "942.6453459262848\n",
      "Word processed done\n",
      "Processing loop 1358\n",
      "merge text\n",
      "0.02300119400024414\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "596.9947919845581\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 51873 sentences\n",
      "956.9281151294708\n",
      "Word processed done\n",
      "Processing loop 1359\n",
      "merge text\n",
      "0.02750229835510254\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "546.0929222106934\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 51996 sentences\n",
      "895.2192094326019\n",
      "Word processed done\n",
      "Processing loop 1360\n",
      "merge text\n",
      "0.03600454330444336\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "699.412291765213\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 54534 sentences\n",
      "903.1530563831329\n",
      "Word processed done\n",
      "Processing loop 1361\n",
      "merge text\n",
      "0.04300260543823242\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "890.107141494751\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 65624 sentences\n",
      "1063.9762642383575\n",
      "Word processed done\n",
      "Processing loop 1362\n",
      "merge text\n",
      "0.03450417518615723\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "869.2190465927124\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 59771 sentences\n",
      "979.00767827034\n",
      "Word processed done\n",
      "Processing loop 1363\n",
      "merge text\n",
      "0.07500433921813965\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "777.2683515548706\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 61884 sentences\n",
      "1101.6588451862335\n",
      "Word processed done\n",
      "Processing loop 1364\n",
      "merge text\n",
      "0.06500363349914551\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "817.0847814083099\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 74863 sentences\n",
      "1356.0243537425995\n",
      "Word processed done\n",
      "Processing loop 1365\n",
      "merge text\n",
      "0.09100532531738281\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1306.1371524333954\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 73617 sentences\n",
      "1244.1171097755432\n",
      "Word processed done\n",
      "Processing loop 1366\n",
      "merge text\n",
      "0.12700748443603516\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "893.4315538406372\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 73408 sentences\n",
      "1250.970766544342\n",
      "Word processed done\n",
      "Processing loop 1367\n",
      "merge text\n",
      "0.10600590705871582\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "905.9836604595184\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 73702 sentences\n",
      "1605.9063200950623\n",
      "Word processed done\n",
      "Processing loop 1368\n",
      "merge text\n",
      "0.3290419578552246\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "972.9825251102448\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 75082 sentences\n",
      "1583.8891770839691\n",
      "Word processed done\n",
      "Processing loop 1369\n",
      "merge text\n",
      "0.21201229095458984\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "989.8633658885956\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 72902 sentences\n",
      "1826.563640832901\n",
      "Word processed done\n",
      "Processing loop 1370\n",
      "merge text\n",
      "0.10300588607788086\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1422.8224885463715\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 66670 sentences\n",
      "1182.2605378627777\n",
      "Word processed done\n",
      "Processing loop 1371\n",
      "merge text\n",
      "0.10500597953796387\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "928.2996611595154\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 72639 sentences\n",
      "1597.0533254146576\n",
      "Word processed done\n",
      "Processing loop 1372\n",
      "merge text\n",
      "0.05800318717956543\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1008.2244460582733\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 75936 sentences\n",
      "1977.6798787117004\n",
      "Word processed done\n",
      "Processing loop 1373\n",
      "merge text\n",
      "0.12851643562316895\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "856.3422162532806\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 70606 sentences\n",
      "1392.209519147873\n",
      "Word processed done\n",
      "Processing loop 1374\n",
      "merge text\n",
      "0.09700560569763184\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "815.2282462120056\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 71706 sentences\n",
      "1347.8755187988281\n",
      "Word processed done\n",
      "Processing loop 1375\n",
      "merge text\n",
      "0.09051156044006348\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "961.3841133117676\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 73190 sentences\n",
      "1426.6048793792725\n",
      "Word processed done\n",
      "Processing loop 1376\n",
      "merge text\n",
      "0.12801003456115723\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1048.2608096599579\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 75111 sentences\n",
      "1405.904061794281\n",
      "Word processed done\n",
      "Processing loop 1377\n",
      "merge text\n",
      "0.07350635528564453\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "1075.2435398101807\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 73527 sentences\n",
      "1685.5962631702423\n",
      "Word processed done\n",
      "Processing loop 1378\n",
      "merge text\n",
      "0.23451614379882812\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "993.1630728244781\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 74808 sentences\n",
      "1482.4481835365295\n",
      "Word processed done\n",
      "Processing loop 1379\n",
      "merge text\n",
      "0.09900569915771484\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "932.3796033859253\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 74746 sentences\n",
      "1612.5076591968536\n",
      "Word processed done\n",
      "Processing loop 1380\n",
      "merge text\n",
      "0.08500480651855469\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 61577\n",
      "10000 / 61577\n",
      "20000 / 61577\n",
      "30000 / 61577\n",
      "40000 / 61577\n",
      "50000 / 61577\n",
      "60000 / 61577\n",
      "herb done\n",
      "drug\n",
      "0 / 26739\n",
      "10000 / 26739\n",
      "20000 / 26739\n",
      "drug done\n",
      "803.0034005641937\n",
      "replace entities done\n",
      "step 2\n",
      "Processing 75145 sentences\n"
     ]
    }
   ],
   "source": [
    "########### Make outdir\n",
    "os.system('mkdir \"..//data//clean_data//noun_verb\"')\n",
    "########### Text source\n",
    "text_list = os.listdir('..//data/abstract_full_1/')[1380:1420]\n",
    "#text_list = ['abstract_00.json']\n",
    "count = 0\n",
    "track = 1380\n",
    "#replaced_list = []\n",
    "textdict = {}\n",
    "#for file in text_list :\n",
    "#for i in range(len(text_list)) :\n",
    "for file in text_list :\n",
    "    textdict = json.load(open('../data/abstract_full_1/%s'%file))\n",
    "    #####\n",
    "    print('Processing loop %s'%track)\n",
    "    text = rmv_n(textdict).lower()\n",
    "    textdict = []\n",
    "    #####\n",
    "    print('step 1')\n",
    "    text = entity_replace(text)\n",
    "    #####\n",
    "    print('step 2')\n",
    "    sentences_processed = word_processing(text,track,stop_and_punctuations)\n",
    "    text = ''\n",
    "    #####\n",
    "    ##### \n",
    "    track+=1\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "#####\n",
    "#entity_replaced.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-035601df330d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mtextdict\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..//data//abstract_full/%s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "########### Make outdir\n",
    "#os.system('mkdir \"..//data//clean_data//only_noun\"')\n",
    "#os.system('mkdir \"..//data//clean_data//only_entity\"')\n",
    "#os.system('mkdir \"..//data//clean_data//without_adjective\"')\n",
    "#os.system('mkdir \"..//data//clean_data//full_sentence\"')\n",
    "os.system('mkdir \"..//data//clean_data//noun_verb\"')\n",
    "########### Text source\n",
    "#text_list = os.listdir('..//data/preprocessing/text_extract/')\n",
    "text_list = os.listdir('..//data/abstract_full/')[:]\n",
    "#text_list = ['abtract_list_26.json']\n",
    "count = 0\n",
    "track = 0\n",
    "#replaced_list = []\n",
    "textdict = []\n",
    "#for file in text_list :\n",
    "#for i in range(len(text_list)) :\n",
    "while text_list != [] :\n",
    "    #####\n",
    "    start = 0\n",
    "    if len(text_list) > 5 :\n",
    "        for num in range(5) :\n",
    "            if start == 0 :\n",
    "                #textdict = json.load(open('..//data//preprocessing//text_extract//%s'%file))\n",
    "                textdict = json.load(open('..//data/abstract_full/%s'%text_list[num]))\n",
    "                start = 1\n",
    "            else :\n",
    "                textdict += json.load(open('..//data//abstract_full/%s'%text_list[num]))\n",
    "        [text_list.pop(0) for i in range(5)]\n",
    "    else :\n",
    "        for num in range(len(text_list)) :\n",
    "            if start == 0 :\n",
    "                #textdict = json.load(open('..//data//preprocessing//text_extract//%s'%file))\n",
    "                textdict = json.load(open('..//data//abstract_full/%s'%text_list[num]))\n",
    "                start = 1\n",
    "            else :\n",
    "                textdict += json.load(open('..//data//abstract_full/%s'%text_list[num]))\n",
    "        [text_list.pop(0) for i in range(len(text_list))]\n",
    "    #####\n",
    "    print('Processing loop %s'%track)\n",
    "    text = rmv_n(textdict)\n",
    "    textdict = []\n",
    "    #####\n",
    "    print('step 1')\n",
    "    (text,replaced_list) = entity_replace(text,replaced_list)\n",
    "    #####\n",
    "    print('step 2')\n",
    "    sentences_processed = word_processing(text,track,stop_words,punctuations)\n",
    "    text = ''\n",
    "    #####\n",
    "    ##### \n",
    "    track+=1\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "#####\n",
    "#entity_replaced.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing loop 0\n",
      "merge text\n",
      "0.1980113983154297\n",
      "merge text done\n",
      "step 1\n",
      "herb\n",
      "0 / 30820\n",
      "1000 / 30820\n",
      "2000 / 30820\n",
      "3000 / 30820\n",
      "4000 / 30820\n",
      "5000 / 30820\n",
      "6000 / 30820\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-ceb61dfe55b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step 1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplaced_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplaced_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m#####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step 2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-9617de803cfa>\u001b[0m in \u001b[0;36mentity_replace\u001b[1;34m(text, replaced_list)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s / %s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mherb_entity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'herb done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########### Text source\n",
    "#text_list = os.listdir('..//data/preprocessing/text_extract/')\n",
    "text_list = ['text_extract_100.json']\n",
    "count = 0\n",
    "track = 0\n",
    "replaced_list = []\n",
    "textdict = []\n",
    "for file in text_list :\n",
    "    if count == 0 :\n",
    "        textdict = json.load(open('..//data//preprocessing//text_extract//%s'%file))\n",
    "        count+=1\n",
    "    elif count < 8 :\n",
    "        textdict.update(json.load(open('..//data//preprocessing//text_extract//%s'%file)))\n",
    "        count+=1\n",
    "    elif count == 8 :\n",
    "        textdict.update(json.load(open('..//data//preprocessing//text_extract//%s'%file)))\n",
    "        count = 0\n",
    "        #####\n",
    "        print('Processing loop %s'%track)\n",
    "        text = rmv_n(textdict)\n",
    "        textdict = []\n",
    "        #####\n",
    "        print('step 1')\n",
    "        (text,replaced_list) = entity_replace(text,replaced_list)\n",
    "        #####\n",
    "        print('step 2')\n",
    "        sentences_processed = word_processing(text)\n",
    "        text = ''\n",
    "        #####\n",
    "        ##### List of processed sentences\n",
    "        outfile = open(os.path.join(outdir,os.path.basename('processed_sentences_%s.json'%track)),'w')\n",
    "        outfile.write(json.dumps(sentences_processed))\n",
    "        outfile.close()\n",
    "        track+=1\n",
    "        sentences_processed = []\n",
    "        \n",
    "#########\n",
    "print('Processing loop %s'%track)\n",
    "text = rmv_n(textdict)\n",
    "textdict = []\n",
    "#####\n",
    "print('step 1')\n",
    "(text,replaced_list) = entity_replace(text,replaced_list)\n",
    "#####\n",
    "print('step 2')\n",
    "sentences_processed = word_processing(text)\n",
    "text = ''\n",
    "#####\n",
    "##### List of processed sentences\n",
    "outfile = open(os.path.join(outdir,os.path.basename('processed_sentences_%s.json'%track)),'w')\n",
    "outfile.write(json.dumps(sentences_processed))\n",
    "outfile.close()\n",
    "\n",
    "#####\n",
    "entity_replaced.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_replaced.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
