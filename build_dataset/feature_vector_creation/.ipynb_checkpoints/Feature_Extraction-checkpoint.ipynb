{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\anaconda1\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5510315895080566\n"
     ]
    }
   ],
   "source": [
    "####### Extract pair entities\n",
    "begin = time.time()\n",
    "os.system('mkdir \"..//..//data//feature_extraction/\"')\n",
    "outdir = '../../data/feature_extraction/'\n",
    "outfile = open(os.path.join(outdir,os.path.basename('entity_pair_sentences.json')),'w')\n",
    "count = 0\n",
    "pairs = []\n",
    "\n",
    "\n",
    "for file in os.listdir('..//../data/clean_data/noun_verb_abs/') :\n",
    "    #####\n",
    "    sentences = json.load(open('..//../data/clean_data/noun_verb_abs/%s'%file))\n",
    "    for sentence in sentences :\n",
    "        num = 0\n",
    "        buf = []\n",
    "        for word in sentence :\n",
    "            if  '_entity_' in word :\n",
    "                num+=1\n",
    "                buf.append(sentence.index(word))\n",
    "        if num == 2 :\n",
    "            if sentence[buf[0]].split('_')[0] != sentence[buf[1]].split('_')[0] and (buf[1] - buf[0]) > 2 :\n",
    "                count+=1\n",
    "                pairs.append([buf,sentence]) \n",
    "                if count % 1000 == 0 :\n",
    "                    print(count)\n",
    "\n",
    "\n",
    "outfile.write(json.dumps(pairs))\n",
    "outfile.close()\n",
    "pairs=[]\n",
    "print(time.time() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen2vec(pair,model,voca):\n",
    "    pos = pair[0]\n",
    "    sentence = pair[1]\n",
    "    #ignore = [ sentence.index(word) for word in sentence if word not in voca ]\n",
    "    res = 0\n",
    "    for i in range(len(sentence)) :\n",
    "        if i not in range(pos[0+1],pos[1]) and sentence[i] in voca :\n",
    "            res+= (0.02*model.wv[sentence[i]])\n",
    "        elif sentence[i] in voca :\n",
    "            f = (1.85*len(sentence))/(pos[1]-pos[0])\n",
    "            res+= (f*model.wv[sentence[i]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 31917\n",
      "2000 / 31917\n",
      "3000 / 31917\n",
      "4000 / 31917\n",
      "5000 / 31917\n",
      "6000 / 31917\n",
      "7000 / 31917\n",
      "8000 / 31917\n",
      "9000 / 31917\n",
      "10000 / 31917\n",
      "11000 / 31917\n",
      "12000 / 31917\n",
      "13000 / 31917\n",
      "14000 / 31917\n",
      "15000 / 31917\n",
      "16000 / 31917\n",
      "17000 / 31917\n",
      "18000 / 31917\n",
      "19000 / 31917\n",
      "20000 / 31917\n",
      "21000 / 31917\n",
      "22000 / 31917\n",
      "23000 / 31917\n",
      "24000 / 31917\n",
      "25000 / 31917\n",
      "26000 / 31917\n",
      "27000 / 31917\n",
      "28000 / 31917\n",
      "29000 / 31917\n",
      "30000 / 31917\n",
      "31000 / 31917\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0851be1134a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mpair_extract\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/feature_extraction/sen_vector.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mre_weight_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mre_weight_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outfile' is not defined"
     ]
    }
   ],
   "source": [
    "#########\n",
    "#########\n",
    "begin = time.time()\n",
    "outdir = '..//../data/feature_extraction/'\n",
    "####\n",
    "path = '..//../data/model/noun_verb_abs/300/model'\n",
    "model = Word2Vec.load(path)\n",
    "voca = list(model.wv.vocab)\n",
    "####\n",
    "pair_extract = json.load(open('..//../data/feature_extraction/entity_pair_sentences.json'))\n",
    "####\n",
    "D = len(pair_extract)\n",
    "re_weight_matrix = np.zeros((D,300),dtype= np.float32)\n",
    "####\n",
    "check = 0\n",
    "for pair in pair_extract :\n",
    "    re_weight_matrix[check] = sen2vec(pair,model,voca)\n",
    "    check+=1\n",
    "    if check % 1000 == 0 :\n",
    "        print('%s / %s'%(check,D))\n",
    "\n",
    "####\n",
    "model = ''\n",
    "voca = ''\n",
    "pair_extract = ''\n",
    "np.save('..//../data/feature_extraction/sen_vector.npy',re_weight_matrix)\n",
    "re_weight_matrix = ''\n",
    "print(time.time() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
