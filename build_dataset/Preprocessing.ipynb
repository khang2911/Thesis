{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Set up Output File\n",
    "outdir = '..//data//clean_data'\n",
    "\n",
    "##### Contain 2 column : 1. Replaced name of entity / 2. Real name of entity\n",
    "reverse_entity = open(os.path.join(outdir,os.path.basename('entity_total.csv')),'w') \n",
    "\n",
    "#####\n",
    "\n",
    "entity_replaced = open(os.path.join(outdir,os.path.basename('entity_replaced.csv')),'w')\n",
    "\n",
    "##### List of processed sentences\n",
    "outfile = open(os.path.join(outdir,os.path.basename('processed_sentences.json')),'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Text source\n",
    "textdict = json.load(open('..//data//preprocessing//text_extract.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Trigger word\n",
    "triggers_raw = open('..//data//preprocessing//triggers.txt').read().split('\\n')[:-1]\n",
    "triggers = []\n",
    "for row in triggers_raw :\n",
    "    triggers.append(row.split('\\t')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Entity sources\n",
    "\n",
    "#### Drug synonyms from drugbank\n",
    "drugs = json.load(open('..//data/preprocessing/drug_corpus/drug_name_synonyms.json'))\n",
    "\n",
    "#### Herb scientific name and its synonyms (not alias)\n",
    "herbs = json.load(open('..//data/preprocessing/herb_corpus/herb_science_synonyms.json'))\n",
    "\n",
    "#### standard ref without effect\n",
    "ref_without = json.load(open('..//data/preprocessing/standard_ref/standard_ref_without_effect.json'))\n",
    "\n",
    "#### standard ref with effect\n",
    "ref_effect = open('..//data/preprocessing/standard_ref/standard_ref_effect.csv',encoding=\"latin-1\").read().split('\\n')[:-1]\n",
    "\n",
    "#### Adverse effect corpus\n",
    "adverse_effect = json.load(open('..//data/preprocessing/adverse_effect_corpus/adverse_effect.json'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create name for entity\n",
    "\n",
    "###### Drug entity\n",
    "drug_entity = {}\n",
    "drugorder = 0\n",
    "for ID in drugs :\n",
    "    for drug in drugs[ID] :\n",
    "        if drug.lower() in herbs or drug.lower() in ref_without :\n",
    "            break\n",
    "        drug_entity[drug.lower()] = 'drug_entity_%s'%drugorder\n",
    "        try :\n",
    "            reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drug.lower()))\n",
    "        except :\n",
    "            drugencode = str(drug.lower()).encode('utf8')\n",
    "            reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drugencode))\n",
    "    drugorder+=1\n",
    "\n",
    "###### Herb entity \n",
    "herb_entity = {}\n",
    "herborder = 0\n",
    "for herb in herbs :\n",
    "    herb_entity[herb.lower()] = 'herb_entity_%s'%herborder\n",
    "    reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herb.lower()))\n",
    "    for synonym in herbs[herb] :\n",
    "        herb_entity[synonym.lower()] = 'herb_entity_%s'%herborder\n",
    "        try :\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,synonym.lower()))\n",
    "        except :\n",
    "            herbencode = str(synonym.lower()).encode('utf8')\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herbencode))\n",
    "    herborder+=1\n",
    "    \n",
    "###### Adverse effect entity\n",
    "effect_entity = {}\n",
    "effectorder = 0\n",
    "for each in adverse_effect :\n",
    "    effect_entity[each.lower()] = 'effect_entity_%s'%effectorder\n",
    "    try :\n",
    "        reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,each.lower()))\n",
    "    except :\n",
    "        effectencode = str(each.lower()).encode('utf8')\n",
    "        reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "    effectorder+=1\n",
    "    \n",
    "###### standard ref without effect entity \n",
    "for herb in ref_without :\n",
    "    if herb.lower() not in herb_entity :\n",
    "        herb_entity[herb.lower()] = 'herb_entity_%s'%herborder\n",
    "        try :\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herb.lower()))\n",
    "        except :\n",
    "            herbencode = str(herb.lower()).encode('utf8')\n",
    "            reverse_entity.write('herb_entity_%s\\t%s\\n'%(herborder,herbencode))\n",
    "        herborder+=1\n",
    "    for drug in ref_without[herb] :\n",
    "        if drug.lower() not in drug_entity :\n",
    "            drug_entity[drug.lower()] = 'drug_entity_%s'%drugorder\n",
    "            try :\n",
    "                reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drug.lower()))\n",
    "            except :\n",
    "                drugencode = str(drug.lower()).encode('utf8')\n",
    "                reverse_entity.write('drug_entity_%s\\t%s\\n'%(drugorder,drugencode))\n",
    "            drugorder+=1\n",
    "            \n",
    "###### standard ref with effect\n",
    "for row in ref_effect :\n",
    "    effect = row.split('\\t')[2]\n",
    "    ###\n",
    "    if effect.lower() not in effect_entity :\n",
    "        effect_entity[effect.lower()] = 'effect_entity_%s'%effectorder\n",
    "        try :\n",
    "            reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,effect.lower()))\n",
    "        except :\n",
    "            effectencode = str(effect.lower()).encode('utf8')\n",
    "            reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "        effectorder+=1\n",
    "    ###    \n",
    "    if len(row.split('\\t')) == 4 :\n",
    "        effect1 = row.split('\\t')[3]\n",
    "        if effect1.lower() not in effect_entity :\n",
    "            effect_entity[effect1.lower()] = 'effect_entity_%s'%effectorder\n",
    "            try :\n",
    "                reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,effect1.lower()))\n",
    "            except :\n",
    "                effectencode = str(effect1.lower()).encode('utf8')\n",
    "                reverse_entity.write('effect_entity_%s\\t%s\\n'%(effectorder,effectencode))\n",
    "            effectorder+=1\n",
    "######\n",
    "reverse_entity.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### remove '\\n' from text and merge text\n",
    "text = ''\n",
    "for each in textdict :\n",
    "    if len(textdict[each].split('\\n')) != 1 :\n",
    "        new = ''.join(textdict[each].split('\\n'))\n",
    "        text+=new\n",
    "    else:\n",
    "        text+= textdict[each]\n",
    "\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug done\n",
      "herb done\n",
      "709.2705476284027\n"
     ]
    }
   ],
   "source": [
    "###### Entity replacement\n",
    "begin = time.time()\n",
    "\n",
    "drug_entity_single = {}\n",
    "for drug in drug_entity :\n",
    "    if len(drug) > 3 :\n",
    "        if drug in text :\n",
    "            text = text.replace(drug,' %s '%drug_entity[drug])\n",
    "            entity_replaced.write('%s\\t%s\\n'%(drug_entity[drug],drug))\n",
    "    else:\n",
    "        drug_entity_single[drug] = drug_entity[drug]\n",
    "\n",
    "print('drug done')\n",
    "    \n",
    "\n",
    "herb_entity_single = {}\n",
    "for herb in herb_entity :\n",
    "    if herb in text :\n",
    "        text = text.replace(herb,' %s '%herb_entity[herb])\n",
    "        entity_replaced.write('%s\\t%s\\n'%(herb_entity[herb],herb))\n",
    "\n",
    "print('herb done')   \n",
    "\n",
    "effect_entity_single = {}\n",
    "for effect in effect_entity :\n",
    "    if len(effect) > 3 :\n",
    "        if effect in text :\n",
    "            text = text.replace(effect,' %s '%effect_entity[effect])\n",
    "            entity_replaced.write('%s\\t%s\\n'%(effect_entity[effect],effect))\n",
    "    else :\n",
    "        effect_entity_single[effect] = effect_entity[effect]\n",
    "    \n",
    "print(time.time() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 59184 sentences\n",
      "Processed 0 sentences\n",
      "Processed 10000 sentences\n",
      "Processed 20000 sentences\n",
      "Processed 30000 sentences\n",
      "Processed 40000 sentences\n",
      "Processed 50000 sentences\n",
      "610.0782999992371\n"
     ]
    }
   ],
   "source": [
    "######## word processing and word removal\n",
    "begin = time.time()\n",
    "count = 0\n",
    "entity_contain = []\n",
    "\n",
    "###### Create pos_tag accept list and stop words list \n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "pos_tag_accept = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ','JJ','JJR','JJS']\n",
    "\n",
    "###### Create entity list \n",
    "reverse_entity = open('..//data/clean_data/entity_total.csv').read().split('\\n')[:-1]\n",
    "entity_list = []\n",
    "for row in reverse_entity :\n",
    "    entity_list.append(row.split('\\t')[0])\n",
    "    \n",
    "entity_list = list(set(entity_list))\n",
    "    \n",
    "###### Split text into sentences\n",
    "sentences = TextBlob(text).sentences\n",
    "total = len(sentences)\n",
    "print('Processing %s sentences'%total)\n",
    "sentences_processed = []\n",
    "\n",
    "###### Processing\n",
    "for sentence in sentences :          \n",
    "    words = word_tokenize(str(sentence)) ##### Split sentence into words and normalization\n",
    "    #####\n",
    "    if len(set(words).intersection(entity_list)) > 2 : ##### Choose sentence contain more than 2 entities\n",
    "        for word in words :\n",
    "            if word in stop_words : ##### Remove stop words\n",
    "                words.pop(words.index(word))\n",
    "            elif len(word) == 1 : ##### Remove punctuation marks\n",
    "                words.pop(words.index(word))    \n",
    "        ###\n",
    "        tags = nltk.pos_tag(words)\n",
    "        for tag in tags :\n",
    "            if tag[0] in triggers or tag[0] in entity_list : ##### Save trigger and entities\n",
    "                pass      \n",
    "            elif tag[1] not in pos_tag_accept : ##### Remove words which are not noun,verb, and adjective \n",
    "                words.pop(words.index(tag[0]))\n",
    "        ###\n",
    "        if len(words) > 2 : ###### Save processed sentence\n",
    "            sentences_processed.append(words)\n",
    "    ###\n",
    "    if count % 10000 == 0 :\n",
    "        print('Processed %s sentences'%count)\n",
    "    count+=1\n",
    "\n",
    "##### \n",
    "print(time.time() - begin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Write Output\n",
    "outfile.write(json.dumps(sentences_processed))\n",
    "outfile.close()\n",
    "entity_replaced.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
